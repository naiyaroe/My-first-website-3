<html>
<link href="https://fonts.googleapis.com/css?family=Nanum+Brush+Script" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Abel|Alegreya+Sans+SC|Dancing+Script|Hind|Rubik" rel="stylesheet">
<style>
body {
    background-color:#F67280 ;
}
h1 {
font-family: ' Nanum Brush Script', cursive;
background-color:#355C7D;
font-size: 30px;
text-align: center;
color: white;
width: 95%;
border: 5px solid black;
align-content: space-between;
margin: 0 auto;
margin-top: 10px;
}
p {
  background-color:#C06C84;
  font-size: 25px;
  text-align: center;
  color: black;
  border: white;
  width: 70%;
  border:  3px dotted white;
  margin: 0 auto;
  margin-top: 20px;
  margin-bottom: 5px;
  font-family: 'Alegreya Sans SC', sans-serif;
}
</style>
<head>
<h1> Ethical Reflection#1 - Machine Bias </h1>
<p>	Usually, technology is thought of as this tool that will make everyone's lives easier. But that is not the case all the time. In a country that supposedly tries to achieve equality, why are they letting a computer determine a person's likelihood of committing a future crime? This already sounds so problematic. In an article by ProPublica about this algorithm giving risk assessment stores based on a survey of various questions and pictures of them, it is shown that 23.5% of defendants that labeled higher risk but didn't re-offend were white and 44.5% of defendants were African-American. Clearly, this computer software is biased. </p>
<p> ProPublica has given many examples of cases where white people have been given lower scores than black people despite having more previous offenses. Because of these scores that exist, judges consider these scores during trial. 
<p> Sources: <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing </a> <a href="https://www.nytimes.com/2017/10/26/opinion/algorithm-compas-sentencing-bias.html"> https://www.nytimes.com/2017/10/26/opinion/algorithm-compas-sentencing-bias.html</a>

</head>
</html>
